Multiple GCP gcloud accounts
	https://stackoverflow.com/a/52728878
	gcloud config configurations list
	gcloud config configurations create YOUR_ACCOUNT_NAME(PICK ANY)
	gcloud auth activate-service-account https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account
	gcloud config configurations activate ACCOUNT_NAME

Enable GCP Compute Engine monitoring for COS (Compute optimized image)
	gcloud compute instances add-metadata INSTANCE_NAME --metadata=google-monitoring-enabled=true
 
Install Redis server on Ubuntu
	https://www.digitalocean.com/community/tutorials/how-to-install-and-secure-redis-on-ubuntu-20-04

SSH into Docker container
	docker ps
	docker exec -it CONTAINER-ID /bin/bash

Login to Google Cloud Compute Engine SSH
	https://stackoverflow.com/a/57087567
		Easiest way for creating and using one pair of ssh keys for multiple instances:
		Step 1: Install putty and puttyGen from https://putty.org/
		Step 2: Open a terminal in your local desktop / laptop (in Windows 10 and later you use Windows Linux Subsystem)
		Type: ssh-keygen
		Enter a name for the filename at the prompt: e.g. google_key
		2 files will be created google_key and google_key.pub
		Step 3: Copy the entire contents of the google_key.pub
		Note there is no new line character. It should all be in one line.
		Step 4: Before creating any VM instance, go to Compute Engine -> Metadata
		Select "SSH keys" tab and click "Add SSH" keys
		Paste the contents of the google_key.pub. If you pasted the contents properly, you should see the username appear on the left label. Then hit save.
		Step 5: Now create your favorite VM instance under google compute.
		Copy the External IP vm_instance_external_ip
		Go back to your linux terminal and type
		ssh -i google_key.pub username@vm_instance_external_ip
		Type "yes"
		And now you should be good to go.

Install Nginx, PHP, MySQL on Ubuntu
	https://www.digitalocean.com/community/tutorials/how-to-install-linux-nginx-mysql-php-lemp-stack-ubuntu-18-04

GCP build errors with artifactregistry.repositories.uploadArtifacts permission missing.
	Go to IAM panel in Console, and add the "Artifact Registry Administrator" role to the principal and check that the repository exists in the Artifact Registry.

View Google Cloud Compute Instance Docker logs
	sudo journalctl -u konlet-startup

Laravel: Drop All Tables and Migrate
	php artisan migrate:fresh --seed

Docker exec console into a container:
	docker exec -it <mycontainer> bash

Laravel retry queue:
	php artisan queue:retry all

Prune Docker outdated images (purge)
	docker system prune -a -f --volumes

Add Google Cloud Logging to Docker on Compute Engine:
	https://cloud.google.com/container-optimized-os/docs/how-to/logging#create_instsance_enabled
	This did not help https://github.com/GoogleCloudPlatform/community/blob/master/archived/docker-gcplogs-driver/index.md#writing-metadata-from-the-cloud-console

Getting a CORS error in browser related to a missing Access-Control-Allow-Origin header in response from storage.googleapis.com
	You should publish the CORS file to your Google Cloud Storage bucket using `D:\web\xny\ticketsarabia> gcloud storage buckets update gs://ticketsarabia_staging --cors-file=google_cloud_storage_cors.json`

	Here are the details https://cloud.google.com/storage/docs/using-cors#command-line_1

Make Google Cloud Storage Bucket public
	Go to PERMISSIONS
	Click GRANT ACCESS
	Add principals: allUsers
	Assign roles: Storage Object Viewer

Google Cloud errors Domain Restricted Sharing when trying to make a bucket public
	In order to still allow specific Cloud Run services being invokeable by allUsers when a DRS policy is in place, platform administrators could disable the DRS policy, set an IAM policy including allUsers and finally enable the DRS policy again.
	https://cloud.google.com/resource-manager/docs/organization-policy/restricting-domains#forcing_access
	
	Disable the policy here https://console.cloud.google.com/iam-admin/orgpolicies/iam-allowedPolicyMemberDomains?authuser=1&inv=1&invt=AbibFw&project=savvy-eats-production

Filament: Call one action after another (open one modal after another)
	https://filamentphp.com/docs/3.x/actions/adding-an-action-to-a-livewire-component#chaining-actions

Docker, Prometheus and Grafana
	How to Set Up Prometheus and Grafana on Docker - A Guide https://signoz.io/guides/how-to-install-prometheus-and-grafana-on-docker/
	Monitor Docker with Prometheus https://docs.docker.com/engine/daemon/prometheus/
	...

Check php-fpm current configuration
	php-fpm -tt

PHP-FPM PM optimization (max_children,..)
	https://gist.github.com/ebta/6ed4fab76bde21006059b2924ff543d5

**The page keeps reloading forever after login:**
	Check that the host and port are in the `SANCTUM_STATEFUL_DOMAINS` list in the `/.env` file.

**The file/image does not upload to Google Cloud Storage and there are no errors**
	Check that the file google-cloud-key.json exists in root of the project. Check the Storage Admin permissions are set for the service account used in GCP.

**Getting a CORS error in browser related to a missing Access-Control-Allow-Origin header in response from storage.googleapis.com**
	You should publish the CORS file to your Google Cloud Storage bucket using `D:\web\xny\ticketsarabia> gcloud storage buckets update gs://ticketsarabia_staging --cors-file=google_cloud_storage_cors_staging.json`

	Here are the details https://cloud.google.com/storage/docs/using-cors#command-line_1

**Getting permission error while running a `gcloud` command, like `does not have permission to access b instance`**
	You are probably authenticated using a wrong account. Check if you have the right account using the command `gcloud auth list`. Then switch to it using the `gcloud config set account ACCOUNT_EMAIL` command.

	Otherwise Google how to authenticate.

**Getting an error while running docker-compose up/watch - ...dl-cdn.alpinelinux.org... temporary error...**
	Need to add the Google DNS server (8.8.8.8) into the Docker daemon.json file:
	https://stackoverflow.com/a/71505749

**The ticket scanner does not request permissions locally.**
	Open the page chrome://flags/#unsafely-treat-insecure-origin-as-secure and input the project's scheme and host there.

**[Fiddler] DNS Lookup for "ticketsarabia.localhost" failed. System.Net.Sockets.SocketException No such host is known**
	Add the ticketsarabia.localhost to the hosts file.

**Docker errors: RUN pecl install imagick: Package "imagick" does not have REST info xml available**
	Just re-run the build. It is a temp. DNS issue. A potential fix is to add the DNS to the Docker daemon setup: `"dns" : ["8.8.8.8", "1.1.1.1"]`.

Laravel Jobs failed, but no output.
	Check the failed_jobs DB table for the clues.

**Getting a network error in browser with a message https://[::1]:5173/...js ERR_CERT_AUTHORITY_INVALID**
	Open the link in a separate browser window and accept the certificate there. By opening Dev tools => network => reload page and right click the error links => open in a new tab => advanced => click the procceed button. After that the page should work correctly.

Do not name files /.env.staging or /.env.production in Laravel, if you do not want Laravel to read those automatically, instead of /.env, when the APP_ENV is defined.

Debug PHP with xDebug
	WinCacheGrind

Reduce Docker image size
	* tools at Github - slim, dive.
	* Linters - hadolint, dockerlinter.
	* copying file is to use the RUN --mount=type=bind,source={localdir},target=/tmp - with this command you can copy data and perform other actions such as installing, uncompromising or anything else in a single layer and the residual size is only what happens at the end

Improve Docker image security:
	* never use the default user - always switch to a lesser privileged one unless absolutely necessary

HTML CSS layout using grid
https://developer.mozilla.org/en-US/docs/Web/CSS/grid-template-areas
grid-template-areas: 
            "a a a"
            "b c c"
            "b c c";

Apache redirect www to non-www (.htaccess)
	RewriteEngine On
	RewriteBase /
	RewriteCond %{HTTP_HOST} ^www\.(.*)$ [NC]
	RewriteRule ^(.*)$ https://%1/$1 [R=301,L]







